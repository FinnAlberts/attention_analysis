# Analysis of Attention Mechanism in Time Series Forecasting

In this repo, you can find our implementation and experimental results of several modifications to the attention mechanism. 

## Article and citations
This repository is part of the article:

"Seduced by the Transformer, Humbled by Simplex: Revisiting Attention for Time Series Forecasting" by Finn Alberts, Ewoud Vosse, and Arjan de Weerd (2025).

The article details the research questions, methods, and findings of this project, exploring how combining Transformers and the Simplex Projection can improve performance for Time Series Forecasting. It builds upon the work from Baljan and Rasoolzadeh Baghmisheh (2024) and therefore uses a fork of their repository as base. If you're interested in the background, methodology, or results, please refer to the article for a comprehensive overview, and is available at [www.finnalberts.nl]([https://finnalberts.nl/projecten/open-universiteit/ai-on-track](https://www.finnalberts.nl/projecten/open-universiteit/seduced-by-the-transformer-humbled-by-simplex)).

If you use this code in your work, please consider citing the article as follows:
```
@article{seducedTranformerHumbledSimplex,
  title={Seduced by the Transformer, Humbled by Simplex: Revisiting Attention for Time Series Forecasting},
  author={Alberts, Finn and Vosse, Ewoud and de Weerd, Arjan},
  year={2025},
  institution={Open Universiteit}
}
```
